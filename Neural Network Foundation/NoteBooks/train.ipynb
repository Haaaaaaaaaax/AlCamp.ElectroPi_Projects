{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'c:\\\\Users\\\\iiven\\\\Ai-Cursor\\\\Neural Network Foundation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\iiven\\\\Ai-Cursor\\\\Neural Network Foundation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Scaled_Data.csv', encoding= 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 444990 entries, 0 to 444989\n",
      "Data columns (total 23 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Quantity   444990 non-null  float64\n",
      " 1   UnitPrice  444990 non-null  float64\n",
      " 2   emb0       444990 non-null  float64\n",
      " 3   emb1       444990 non-null  float64\n",
      " 4   emb2       444990 non-null  float64\n",
      " 5   emb3       444990 non-null  float64\n",
      " 6   emb4       444990 non-null  float64\n",
      " 7   emb5       444990 non-null  float64\n",
      " 8   emb6       444990 non-null  float64\n",
      " 9   emb7       444990 non-null  float64\n",
      " 10  emb8       444990 non-null  float64\n",
      " 11  emb9       444990 non-null  float64\n",
      " 12  emb10      444990 non-null  float64\n",
      " 13  emb11      444990 non-null  float64\n",
      " 14  emb12      444990 non-null  float64\n",
      " 15  emb13      444990 non-null  float64\n",
      " 16  emb14      444990 non-null  float64\n",
      " 17  emb15      444990 non-null  float64\n",
      " 18  emb16      444990 non-null  float64\n",
      " 19  emb17      444990 non-null  float64\n",
      " 20  emb18      444990 non-null  float64\n",
      " 21  emb19      444990 non-null  float64\n",
      " 22  Country    444990 non-null  float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 78.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>emb0</th>\n",
       "      <th>emb1</th>\n",
       "      <th>emb2</th>\n",
       "      <th>emb3</th>\n",
       "      <th>emb4</th>\n",
       "      <th>emb5</th>\n",
       "      <th>emb6</th>\n",
       "      <th>emb7</th>\n",
       "      <th>...</th>\n",
       "      <th>emb11</th>\n",
       "      <th>emb12</th>\n",
       "      <th>emb13</th>\n",
       "      <th>emb14</th>\n",
       "      <th>emb15</th>\n",
       "      <th>emb16</th>\n",
       "      <th>emb17</th>\n",
       "      <th>emb18</th>\n",
       "      <th>emb19</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.242725</td>\n",
       "      <td>-0.118623</td>\n",
       "      <td>1.712810</td>\n",
       "      <td>-1.067008</td>\n",
       "      <td>2.891698</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-1.128504</td>\n",
       "      <td>-0.419209</td>\n",
       "      <td>0.408398</td>\n",
       "      <td>0.440412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428867</td>\n",
       "      <td>-0.690679</td>\n",
       "      <td>1.610313</td>\n",
       "      <td>-1.841917</td>\n",
       "      <td>-0.305638</td>\n",
       "      <td>-1.123742</td>\n",
       "      <td>-0.189980</td>\n",
       "      <td>0.351855</td>\n",
       "      <td>-2.351553</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242725</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>-1.198519</td>\n",
       "      <td>-1.227486</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>-0.652827</td>\n",
       "      <td>-0.708485</td>\n",
       "      <td>-0.771444</td>\n",
       "      <td>0.805523</td>\n",
       "      <td>0.032484</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279992</td>\n",
       "      <td>-0.749484</td>\n",
       "      <td>0.045945</td>\n",
       "      <td>-0.589374</td>\n",
       "      <td>-0.609605</td>\n",
       "      <td>0.255710</td>\n",
       "      <td>-0.416097</td>\n",
       "      <td>-0.114442</td>\n",
       "      <td>-0.040132</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.688081</td>\n",
       "      <td>-0.020650</td>\n",
       "      <td>1.534431</td>\n",
       "      <td>-0.571380</td>\n",
       "      <td>1.440769</td>\n",
       "      <td>-1.139276</td>\n",
       "      <td>0.426717</td>\n",
       "      <td>0.757892</td>\n",
       "      <td>-0.885712</td>\n",
       "      <td>0.162420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312307</td>\n",
       "      <td>1.046334</td>\n",
       "      <td>1.257849</td>\n",
       "      <td>0.143399</td>\n",
       "      <td>-0.065791</td>\n",
       "      <td>-1.083560</td>\n",
       "      <td>-0.889989</td>\n",
       "      <td>-0.434721</td>\n",
       "      <td>-1.032786</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242725</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>1.885662</td>\n",
       "      <td>-0.106293</td>\n",
       "      <td>-0.223947</td>\n",
       "      <td>-1.124037</td>\n",
       "      <td>0.605544</td>\n",
       "      <td>-1.238311</td>\n",
       "      <td>-0.084702</td>\n",
       "      <td>1.891655</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.104609</td>\n",
       "      <td>0.067654</td>\n",
       "      <td>0.770832</td>\n",
       "      <td>-0.551257</td>\n",
       "      <td>0.122419</td>\n",
       "      <td>-1.338668</td>\n",
       "      <td>0.182438</td>\n",
       "      <td>-1.750836</td>\n",
       "      <td>0.709788</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.242725</td>\n",
       "      <td>0.292864</td>\n",
       "      <td>1.343033</td>\n",
       "      <td>0.880794</td>\n",
       "      <td>1.995304</td>\n",
       "      <td>-2.247623</td>\n",
       "      <td>-1.194081</td>\n",
       "      <td>-1.266475</td>\n",
       "      <td>-0.047135</td>\n",
       "      <td>0.325198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145468</td>\n",
       "      <td>1.123368</td>\n",
       "      <td>0.726530</td>\n",
       "      <td>-1.835686</td>\n",
       "      <td>1.769276</td>\n",
       "      <td>-0.487526</td>\n",
       "      <td>-2.103928</td>\n",
       "      <td>0.132345</td>\n",
       "      <td>-0.374595</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quantity  UnitPrice      emb0      emb1      emb2      emb3      emb4  \\\n",
       "0  0.242725  -0.118623  1.712810 -1.067008  2.891698 -1.055426 -1.128504   \n",
       "1  0.242725   0.292864 -1.198519 -1.227486 -0.000488 -0.652827 -0.708485   \n",
       "2  0.688081  -0.020650  1.534431 -0.571380  1.440769 -1.139276  0.426717   \n",
       "3  0.242725   0.292864  1.885662 -0.106293 -0.223947 -1.124037  0.605544   \n",
       "4  0.242725   0.292864  1.343033  0.880794  1.995304 -2.247623 -1.194081   \n",
       "\n",
       "       emb5      emb6      emb7  ...     emb11     emb12     emb13     emb14  \\\n",
       "0 -0.419209  0.408398  0.440412  ... -0.428867 -0.690679  1.610313 -1.841917   \n",
       "1 -0.771444  0.805523  0.032484  ...  1.279992 -0.749484  0.045945 -0.589374   \n",
       "2  0.757892 -0.885712  0.162420  ... -0.312307  1.046334  1.257849  0.143399   \n",
       "3 -1.238311 -0.084702  1.891655  ... -1.104609  0.067654  0.770832 -0.551257   \n",
       "4 -1.266475 -0.047135  0.325198  ...  0.145468  1.123368  0.726530 -1.835686   \n",
       "\n",
       "      emb15     emb16     emb17     emb18     emb19  Country  \n",
       "0 -0.305638 -1.123742 -0.189980  0.351855 -2.351553     36.0  \n",
       "1 -0.609605  0.255710 -0.416097 -0.114442 -0.040132     36.0  \n",
       "2 -0.065791 -1.083560 -0.889989 -0.434721 -1.032786     36.0  \n",
       "3  0.122419 -1.338668  0.182438 -1.750836  0.709788     36.0  \n",
       "4  1.769276 -0.487526 -2.103928  0.132345 -0.374595     36.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dummy_df = train_test_split(df, test_size= 0.2, shuffle= True, random_state= 42)\n",
    "val_df , test_df = train_test_split(dummy_df, test_size=0.5, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355992, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44499, 23)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44499, 23)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['UnitPrice']\n",
    "features = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('UnitPrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quantity',\n",
       " 'emb0',\n",
       " 'emb1',\n",
       " 'emb2',\n",
       " 'emb3',\n",
       " 'emb4',\n",
       " 'emb5',\n",
       " 'emb6',\n",
       " 'emb7',\n",
       " 'emb8',\n",
       " 'emb9',\n",
       " 'emb10',\n",
       " 'emb11',\n",
       " 'emb12',\n",
       " 'emb13',\n",
       " 'emb14',\n",
       " 'emb15',\n",
       " 'emb16',\n",
       " 'emb17',\n",
       " 'emb18',\n",
       " 'emb19',\n",
       " 'Country']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tensor(df):\n",
    "    x = torch.tensor(df[features].values, dtype= torch.float32)\n",
    "    y = torch.tensor(df[target].values, dtype= torch.float32)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_to_tensor(train_df)\n",
    "X_val, y_val = df_to_tensor(val_df)\n",
    "X_test, y_test = df_to_tensor(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds = TensorDataset(X_val, y_val)\n",
    "test_ds = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden1, hidden2, dropout_rate, output_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\")\n",
    "        \n",
    "        for X_batch, y_batch in train_loop:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "                val_outputs = model(X_val_batch)\n",
    "                loss = criterion(val_outputs, y_val_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} â€” Training Loss: {total_loss/len(train_loader):.4f}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adamax\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 1\n",
    "hidden1 = 128\n",
    "hidden2 = 64\n",
    "dropout_rate = 0.3\n",
    "model = ANNModel(input_size, hidden1, hidden2, dropout_rate, output_size)\n",
    "otimizer = Adamax(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:13<00:00, 301.77it/s, loss=0.468] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 â€” Training Loss: 0.5687, Validation Loss: 0.4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:13<00:00, 302.98it/s, loss=1.65]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 â€” Training Loss: 0.5581, Validation Loss: 0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:13<00:00, 302.07it/s, loss=0.35]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 â€” Training Loss: 0.5474, Validation Loss: 0.4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:15<00:00, 293.39it/s, loss=1.01]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 â€” Training Loss: 0.5400, Validation Loss: 0.4605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:15<00:00, 295.87it/s, loss=0.268] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 â€” Training Loss: 0.5332, Validation Loss: 0.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:13<00:00, 302.80it/s, loss=0.321] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 â€” Training Loss: 0.5251, Validation Loss: 0.4480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:13<00:00, 302.51it/s, loss=0.211] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 â€” Training Loss: 0.5187, Validation Loss: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:13<00:00, 300.83it/s, loss=0.707] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 â€” Training Loss: 0.5127, Validation Loss: 0.4308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:14<00:00, 300.15it/s, loss=0.374] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 â€” Training Loss: 0.5055, Validation Loss: 0.4246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22250/22250 [01:14<00:00, 298.96it/s, loss=0.96]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 â€” Training Loss: 0.5010, Validation Loss: 0.4185\n"
     ]
    }
   ],
   "source": [
    "train_model(model= model, train_loader= train_loader, val_loader= val_loader, optimizer= otimizer, criterion= criterion, epochs= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def predict_and_evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            preds.append(outputs.cpu().numpy())\n",
    "            targets.append(y_batch.numpy())\n",
    "\n",
    "    preds = np.vstack(preds).squeeze()\n",
    "    targets = np.vstack(targets).squeeze()\n",
    "\n",
    "    rmse = mean_squared_error(targets, preds) ** 0.5\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    r2 = r2_score(targets, preds)\n",
    "\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.6485\n",
      "Test MAE: 0.4688\n",
      "Test R2 Score: 0.5806\n"
     ]
    }
   ],
   "source": [
    "predict_and_evaluate(model= model, test_loader= test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0.58 percent is really bad**<br>\n",
    "**options to get more accuracy**<br>\n",
    "- Use more features from PCA\n",
    "- Add regulization so it doesn't overfit or underfit\n",
    "- Tuning hyperparameters using optuna for example\n",
    "- Use pretrained models for more advanced architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ANN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
